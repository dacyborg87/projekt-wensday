# Projekt Wensday ü§ñüé∑  
A ‚ÄúJarvis-style‚Äù CLI assistant that streams replies in real time and speaks them out loud using **ElevenLabs** TTS ‚Äî built as a hands-on AI + automation project for my cybersecurity journey.  
  
> **Status:** Working (streaming text + voice playback)  
  
## What it does (today)  
- Streams Wensday‚Äôs response to your terminal **live** (token-by-token / chunk-by-chunk)  
- Converts the response into speech using **ElevenLabs streaming TTS**  
- Plays audio on macOS using `afplay`  
- Includes a near-real-time pipeline:  
  - stream text ‚Üí split into sentence chunks ‚Üí queue ‚Üí background TTS worker ‚Üí play  
  
## Tech stack  
- Python 3  
- OpenAI (text generation / streaming)  
- ElevenLabs (streaming text-to-speech)  
- `requests` (HTTP streaming)  
- macOS `afplay` (audio playback)  
  
## Project structure (recommended)  
```text  
projekt-wensday/  
‚îú‚îÄ‚îÄ wensday_cli.py  
‚îú‚îÄ‚îÄ wensday_voice.py  
‚îú‚îÄ‚îÄ README.md  
‚îú‚îÄ‚îÄ requirements.txt  
‚îú‚îÄ‚îÄ .env.example  
‚îî‚îÄ‚îÄ docs/  
    ‚îú‚îÄ‚îÄ SETUP.md  
    ‚îú‚îÄ‚îÄ ARCHITECTURE.md  
    ‚îî‚îÄ‚îÄ ROADMAP.md  
```  
  
## Requirements  
- macOS (recommended) or any OS with an audio player you can swap in  
- Python 3.10+ (you can run newer versions too)  
- API keys:  
  - `OPENAI_API_KEY`  
  - `ELEVENLABS_API_KEY`  
  - `ELEVENLABS_VOICE_ID`  
  
## Quick start (macOS)  
### 1) Create & activate a virtual environment  
```bash  
python3 -m venv venv  
source venv/bin/activate  
```  
### 2) Install dependencies  
```bash  
pip install -r requirements.txt  
```  
### 3) Set environment variables (temporary for this terminal)  
```bash  
export OPENAI_API_KEY="YOUR_OPENAI_KEY"  
export ELEVENLABS_API_KEY="YOUR_ELEVENLABS_KEY"  
export ELEVENLABS_VOICE_ID="YOUR_VOICE_ID"  
```  
(Optional tuning)  
```bash  
export ELEVENLABS_STABILITY="0.35"  
export ELEVENLABS_SIMILARITY_BOOST="0.80"  
export ELEVENLABS_STYLE="0.35"  
```  
### 4) Run the CLI  
```bash  
python3 wensday_cli.py  
```  
Type `exit` to quit.  
  
## Notes  
- This project streams audio chunk-by-chunk, so you‚Äôll hear Wensday speaking while the response is still being generated.  
- If you‚Äôre not on macOS, replace `afplay` with your OS audio command (see `docs/SETUP.md`).  
  
## Why I built this  
I‚Äôm building Projekt Wensday as a real portfolio project that combines:  
- AI assistant behavior  
- streaming UX  
- voice interfaces  
- automation patterns (queues, threads, chunking)  
- and a path toward a cybersecurity ‚Äúcopilot‚Äù for my labs (Wazuh, Suricata, etc.)  
  
## Roadmap  
Planned next:  
- Memory (short-term + long-term)  
- ‚ÄúCyber Copilot‚Äù mode (log parsing, alert explanations, runbooks)  
- Config file for voices + settings  
- Optional UI layer (local dashboard)  
  
See `docs/ROADMAP.md`.  
  
## License  
Choose one (MIT recommended) once the repo is public. 
